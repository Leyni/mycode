{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://github.com/applenob/simple_crf/blob/master/crf.py\n",
    "\n",
    "import numpy as np\n",
    "from scipy import special, optimize\n",
    "\n",
    "# 引进特殊的起点和终点标记\n",
    "START = '|-'\n",
    "END = '-1'\n",
    "\n",
    "def log_dot_vm(loga, logM):\n",
    "    \"\"\"通过log向量和log矩阵，计算log(向量 点乘 矩阵)\"\"\"\n",
    "    return special.logsumexp(np.expand_dims(loga, axis=1) + logM, axis=0)\n",
    "\n",
    "\n",
    "def log_dot_mv(logM, logb):\n",
    "    \"\"\"通过log向量和log矩阵，计算log(矩阵 点乘 向量)\"\"\"\n",
    "    return special.logsumexp(logM + np.expand_dims(logb, axis=0), axis=1)\n",
    "\n",
    "\n",
    "class CRF:\n",
    "    def __init__(self, feature_functions, labels):\n",
    "        self.ft_fun = feature_functions\n",
    "        self.k = len(self.ft_fun)\n",
    "        self.w = np.random.randn(self.k)\n",
    "        self.labels = labels\n",
    "        self.label_id = {l: i for i, l in enumerate(self.labels)}\n",
    "        \n",
    "    def train(self, x_vecs, y_vecs):\n",
    "        vectorised_x_vecs, vectorised_y_vecs = self.create_vector_list(x_vecs, y_vecs)\n",
    "        l = lambda w: self.neg_likelihood_and_deriv(vectorised_x_vecs, vectorised_y_vecs, w)\n",
    "        val = optimize.fmin_l_bfgs_b(l, self.w)\n",
    "        self.w, _, _ = val\n",
    "        return self.w\n",
    "        \n",
    "    # for train()\n",
    "    def create_vector_list(self,x_vecs, y_vecs):\n",
    "        observations = [self.get_all_features(x_vec) for x_vec in x_vecs]\n",
    "        labels = len(y_vecs) * [None]\n",
    "\n",
    "        for i in range(len(y_vecs)):\n",
    "            y_vecs[i].insert(0, START)\n",
    "            y_vecs[i].append(END)\n",
    "            labels[i] = np.array([self.label_id[y] for y in y_vecs[i]], copy=False, dtype=np.int)\n",
    "        return observations, labels\n",
    "        \n",
    "    # for create_vector_list()\n",
    "    def get_all_features(self, x_vec):\n",
    "        result = np.zeros((len(x_vec) + 1, len(self.labels), len(self.labels), len(self.ft_fun)))\n",
    "        for i in range(len(x_vec) + 1):\n",
    "            for j, yp in enumerate(self.labels):\n",
    "                for k, y in enumerate(self.labels):\n",
    "                    for l, f in enumerate(self.ft_fun):\n",
    "                        result[i, j, k, l] = f(yp, y, x_vec, i)\n",
    "        return result\n",
    "    \n",
    "    # for train()\n",
    "    def neg_likelihood_and_deriv(self, x_vec_list, y_vec_list, w):\n",
    "        \"\"\"        \n",
    "        求负对数似然函数和关于w的偏导。\n",
    "        关键变量的尺寸中，Y是标注空间的个数，K是特征函数的个数。\n",
    "        \"\"\"\n",
    "        likelihood = 0\n",
    "        derivative = np.zeros(len(self.w))\n",
    "        \n",
    "        for x_vec, y_vec in zip(x_vec_list, y_vec_list):\n",
    "            all_features = x_vec\n",
    "            length = x_vec.shape[0]\n",
    "            yp_vec_ids = y_vec[:-1]\n",
    "            y_vec_ids = y_vec[1:]\n",
    "            log_M_s = np.dot(all_features, w)\n",
    "            \n",
    "            log_alphas = self.forward(log_M_s, self.label_id[START])\n",
    "            log_betas = self.backward(log_M_s, self.label_id[END])\n",
    "            \n",
    "            last = log_alphas[-1]\n",
    "            log_Z = special.logsumexp(last)\n",
    "            \n",
    "            log_alphas1 = np.expand_dims(log_alphas[1:], axis=2)\n",
    "            log_betas1 = np.expand_dims(log_betas[:-1], axis=1)\n",
    "            \n",
    "            log_probs = log_alphas1 + log_M_s + log_betas1 - log_Z\n",
    "            log_probs = np.expand_dims(log_probs, axis=3)\n",
    "            \n",
    "            # 计算特征函数关于模型的期望\n",
    "            exp_features = np.sum(np.exp(log_probs) * all_features, axis=(0, 1, 2))\n",
    "            # 计算特征函数关于训练数据的期望\n",
    "            emp_features = np.sum(all_features[range(length), yp_vec_ids, y_vec_ids], axis=0)\n",
    "            \n",
    "            # 计算似然函数\n",
    "            likelihood += np.sum(log_M_s[range(length), yp_vec_ids, y_vec_ids]) - log_Z\n",
    "            # 计算似然函数的偏导\n",
    "            derivative += emp_features - exp_features\n",
    "\n",
    "        return -likelihood, -derivative\n",
    "    \n",
    "    # for neg_likelihood_and_deriv()\n",
    "    def forward(self, log_M_s, start):\n",
    "        T = log_M_s.shape[0]\n",
    "        Y = log_M_s.shape[1]\n",
    "        alphas = np.NINF * np.ones((T+1, Y))  # log0 = ninf\n",
    "        alpha = alphas[0]\n",
    "        alpha[start] = 0  # log1 = 0\n",
    "        for t in range(1, T+1):\n",
    "            alphas[t] = log_dot_vm(alpha, log_M_s[t - 1])\n",
    "            alpha = alphas[t]\n",
    "        return alphas\n",
    "\n",
    "    # for neg_likelihood_and_deriv()\n",
    "    def backward(self, log_M_s, end):\n",
    "        T = log_M_s.shape[0]\n",
    "        Y = log_M_s.shape[1]\n",
    "        betas = np.NINF * np.ones((T+1, Y))  # log0 = ninf\n",
    "        # betas = np.zeros((T+1, Y))\n",
    "        beta = betas[-1]\n",
    "        beta[end] = 0  # log1 = 0\n",
    "        for t in reversed(range(T)):\n",
    "            betas[t] = log_dot_mv(log_M_s[t], beta)\n",
    "            beta = betas[t]\n",
    "        return betas\n",
    "    \n",
    "    def predict(self, x_vec, debug=False):\n",
    "        \"\"\"\n",
    "        给定x，预测y。使用Viterbi算法\n",
    "        \"\"\"\n",
    "        \n",
    "        # all_features, len(x_vec) + 1, Y, Y, K\n",
    "        all_features = self.get_all_features(x_vec)\n",
    "        \n",
    "        # log_potential: len(x_vec) + 1, Y, Y  保存各个下标的非规范化概率\n",
    "        log_potential = np.dot(all_features, self.w)\n",
    "        \n",
    "        T = len(x_vec)\n",
    "        Y = len(self.labels)\n",
    "        \n",
    "        # Psi保存每个时刻最优情况的下标\n",
    "        Psi = np.ones((T, Y), dtype=np.int32) * -1\n",
    "        \n",
    "        # 初始化\n",
    "        delta = log_potential[0, 0]\n",
    "        \n",
    "        # 递推\n",
    "        for t in range(1, T):\n",
    "            next_delta = np.zeros(Y)\n",
    "            for y in range(Y):\n",
    "                w = delta + log_potential[t, :, y]\n",
    "                Psi[t, y] = psi = w.argmax()\n",
    "                next_delta[y] = w[psi]\n",
    "            delta = next_delta\n",
    "            \n",
    "        # 回溯找到最优路径\n",
    "        y = delta.argmax()\n",
    "        trace = []\n",
    "        for t in reversed(range(T)):\n",
    "            trace.append(y)\n",
    "            y = Psi[t, y]\n",
    "        trace.reverse()\n",
    "        return [self.labels[i] for i in trace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get feature functions ...\n",
      "('raw data: ', ['Confidence', 'in', 'the', 'pound', 'is', 'widely', 'expected', 'to', 'take', 'another', 'sharp', 'dive', 'if', 'trade', 'figures', 'for', 'September', ',', 'due', 'for', 'release', 'tomorrow', ',', 'fail', 'to', 'show', 'a', 'substantial', 'improvement', 'from', 'July', 'and', 'August', \"'s\", 'near-record', 'deficits', '.'])\n",
      "('prediction: ', ['NN', 'CD', 'VBN', 'IN', 'VBZ', 'VBZ', 'VBZ', 'PRP$', 'VBZ', 'NN', 'POS', '|-', 'NN', 'POS', 'JJ', 'VBP', '|-', 'NN', 'IN', 'RB', '-1', '-1', '.', 'VBG', 'PRP$', 'IN', 'VBZ', 'PRP$', '|-', 'NN', 'POS', 'VBG', 'DT', 'RB', '-1', 'RB', 'VBP'])\n",
      "('ground truth: ', ['|-', 'NN', 'IN', 'DT', 'NN', 'VBZ', 'RB', 'VBN', 'TO', 'VB', 'DT', 'JJ', 'NN', 'IN', 'NN', 'NNS', 'IN', 'NNP', ',', 'JJ', 'IN', 'NN', 'NN', ',', 'VB', 'TO', 'VB', 'DT', 'JJ', 'NN', 'IN', 'NNP', 'CC', 'NNP', 'POS', 'JJ', 'NNS', '.', '-1'])\n",
      "('raw data: ', ['Chancellor', 'of', 'the', 'Exchequer', 'Nigel', 'Lawson', \"'s\", 'restated', 'commitment', 'to', 'a', 'firm', 'monetary', 'policy', 'has', 'helped', 'to', 'prevent', 'a', 'freefall', 'in', 'sterling', 'over', 'the', 'past', 'week', '.'])\n",
      "('prediction: ', ['RB', '-1', 'VBG', 'DT', 'NNS', 'VBP', 'VBN', 'NNS', 'VBZ', 'PRP$', 'VBZ', 'PRP$', 'CC', 'VBG', '-1', 'RB', 'VBZ', 'PRP$', 'VBZ', 'PRP$', 'IN', '-1', 'RB', '-1', '-1', '-1', 'VBP'])\n",
      "('ground truth: ', ['|-', 'NNP', 'IN', 'DT', 'NNP', 'NNP', 'NNP', 'POS', 'VBN', 'NN', 'TO', 'DT', 'NN', 'JJ', 'NN', 'VBZ', 'VBN', 'TO', 'VB', 'DT', 'NN', 'IN', 'NN', 'IN', 'DT', 'JJ', 'NN', '.', '-1'])\n",
      "('raw data: ', ['But', 'analysts', 'reckon', 'underlying', 'support', 'for', 'sterling', 'has', 'been', 'eroded', 'by', 'the', 'chancellor', \"'s\", 'failure', 'to', 'announce', 'any', 'new', 'policy', 'measures', 'in', 'his', 'Mansion', 'House', 'speech', 'last', 'Thursday', '.'])\n",
      "('prediction: ', ['IN', '|-', 'NN', 'DT', 'NNS', 'VBP', '-1', 'VBG', 'DT', 'RB', 'VBP', 'VBN', 'CD', 'VBN', 'NNS', 'VBZ', 'VBZ', 'NN', 'POS', 'VBG', 'DT', 'NNS', 'VBP', 'VBN', 'VB', 'NN', 'TO', 'CD', 'VBN'])\n",
      "('ground truth: ', ['|-', 'CC', 'NNS', 'VBP', 'VBG', 'NN', 'IN', 'NN', 'VBZ', 'VBN', 'VBN', 'IN', 'DT', 'NN', 'POS', 'NN', 'TO', 'VB', 'DT', 'JJ', 'NN', 'NNS', 'IN', 'PRP$', 'NNP', 'NNP', 'NN', 'JJ', 'NNP', '.', '-1'])\n",
      "('raw data: ', ['This', 'has', 'increased', 'the', 'risk', 'of', 'the', 'government', 'being', 'forced', 'to', 'increase', 'base', 'rates', 'to', '16', '%', 'from', 'their', 'current', '15', '%', 'level', 'to', 'defend', 'the', 'pound', ',', 'economists', 'and', 'foreign', 'exchange', 'market', 'analysts', 'say', '.'])\n",
      "('prediction: ', ['NN', 'TO', 'CD', 'VBN', 'VB', 'PRP$', 'VBN', 'CC', 'VBG', 'DT', 'PRP$', 'VBZ', 'PRP$', 'TO', 'POS', 'VBG', 'DT', 'PRP$', ',', '|-', 'NN', 'POS', 'TO', 'POS', 'TO', 'VBN', 'IN', 'NN', 'POS', 'VBG', '-1', 'RB', '-1', 'RB', '-1', 'VBP'])\n",
      "('ground truth: ', ['|-', 'DT', 'VBZ', 'VBN', 'DT', 'NN', 'IN', 'DT', 'NN', 'VBG', 'VBN', 'TO', 'VB', 'NN', 'NNS', 'TO', 'CD', 'NN', 'IN', 'PRP$', 'JJ', 'CD', 'NN', 'NN', 'TO', 'VB', 'DT', 'NN', ',', 'NNS', 'CC', 'JJ', 'NN', 'NN', 'NNS', 'VBP', '.', '-1'])\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "import sys\n",
    "\n",
    "def get_feature_functions(word_sets, labels, observes):\n",
    "    \"\"\"生成各种特征函数\"\"\"\n",
    "    print(\"get feature functions ...\")\n",
    "    transition_functions = [\n",
    "        lambda yp, y, x_v, i, _yp=_yp, _y=_y: \n",
    "        1 if yp == _yp and y == _y else 0\n",
    "        for _yp in labels[:-1] for _y in labels[1:]\n",
    "        ]\n",
    "\n",
    "    def set_membership(tag, word_sets):\n",
    "        def fun(yp, y, x_v, i):\n",
    "            if i < len(x_v) and x_v[i].lower() in word_sets[tag]:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        return fun\n",
    "\n",
    "    observation_functions = [set_membership(t, word_sets) for t in word_sets]\n",
    "\n",
    "    misc_functions = [\n",
    "        lambda yp, y, x_v, i: 1 if i < len(x_v) and re.match('^[^0-9a-zA-Z]+$', x_v[i]) else 0,\n",
    "        lambda yp, y, x_v, i: 1 if i < len(x_v) and re.match('^[A-Z\\.]+$', x_v[i]) else 0,\n",
    "        lambda yp, y, x_v, i: 1 if i < len(x_v) and re.match('^[0-9\\.]+$', x_v[i]) else 0\n",
    "    ]\n",
    "\n",
    "    tagval_functions = [\n",
    "        lambda yp, y, x_v, i, _y=_y, _x=_x: 1 if i < len(x_v) and y == _y and x_v[i].lower() == _x else 0\n",
    "        for _y in labels\n",
    "        for _x in observes]\n",
    "\n",
    "    return transition_functions + tagval_functions + observation_functions + misc_functions\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    word_data = []\n",
    "    label_data = []\n",
    "    all_labels = set()\n",
    "    word_sets = defaultdict(set)\n",
    "    observes = set()\n",
    "    \n",
    "    data = [\n",
    "        \"Confidence/NN in/IN the/DT pound/NN is/VBZ widely/RB expected/VBN to/TO take/VB another/DT sharp/JJ dive/NN if/IN trade/NN figures/NNS for/IN September/NNP ,/, due/JJ for/IN release/NN tomorrow/NN ,/, fail/VB to/TO show/VB a/DT substantial/JJ improvement/NN from/IN July/NNP and/CC August/NNP 's/POS near-record/JJ deficits/NNS ./.\",\n",
    "        \"Chancellor/NNP of/IN the/DT Exchequer/NNP Nigel/NNP Lawson/NNP 's/POS restated/VBN commitment/NN to/TO a/DT firm/NN monetary/JJ policy/NN has/VBZ helped/VBN to/TO prevent/VB a/DT freefall/NN in/IN sterling/NN over/IN the/DT past/JJ week/NN ./.\",\n",
    "        \"But/CC analysts/NNS reckon/VBP underlying/VBG support/NN for/IN sterling/NN has/VBZ been/VBN eroded/VBN by/IN the/DT chancellor/NN 's/POS failure/NN to/TO announce/VB any/DT new/JJ policy/NN measures/NNS in/IN his/PRP$ Mansion/NNP House/NNP speech/NN last/JJ Thursday/NNP ./.\",\n",
    "        \"This/DT has/VBZ increased/VBN the/DT risk/NN of/IN the/DT government/NN being/VBG forced/VBN to/TO increase/VB base/NN rates/NNS to/TO 16/CD %/NN from/IN their/PRP$ current/JJ 15/CD %/NN level/NN to/TO defend/VB the/DT pound/NN ,/, economists/NNS and/CC foreign/JJ exchange/NN market/NN analysts/NNS say/VBP ./.\",\n",
    "    ]\n",
    "    \n",
    "    for line in data:\n",
    "        words, labels = [], []\n",
    "        for token in line.strip().split():\n",
    "            word, label = token.split('/')\n",
    "            all_labels.add(label)\n",
    "            word_sets[label].add(word.lower())\n",
    "            observes.add(word.lower())\n",
    "            words.append(word)\n",
    "            labels.append(label)\n",
    "\n",
    "        word_data.append(words)\n",
    "        label_data.append(labels)\n",
    "\n",
    "    labels = [START, END] + list(all_labels)\n",
    "    feature_functions = get_feature_functions(word_sets, labels, observes)\n",
    "\n",
    "    crf = CRF(labels=labels, feature_functions=feature_functions)\n",
    "    crf.train(word_data, label_data)\n",
    "    for x_vec, y_vec in zip(word_data[-5:], label_data[-5:]):\n",
    "        print(\"raw data: \", x_vec)\n",
    "        print(\"prediction: \", crf.predict(x_vec))\n",
    "        print(\"ground truth: \", y_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
