{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    dataSet = [[1, 1, 'yes'], # 构建特征值\n",
    "            [1, 1, 'yes'],\n",
    "            [1, 0, 'no'],\n",
    "            [0, 1, 'no'],\n",
    "            [0, 1, 'no'],\n",
    "            ]\n",
    "    labels = ['no surfacing', 'flippers'] # 特征属性描述\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcShannonEnt(dataSet):\n",
    "    \"\"\"\n",
    "    function: 计算样本集的香农熵\n",
    "\n",
    "    dataSet: type List[List[]]\n",
    "    return : type float\n",
    "    \"\"\"\n",
    "\n",
    "    numEntries = len(dataSet) # 计算总样本量，用于计算各类型样本出现概率的分母\n",
    "    labelCounts = {} # 用于存储每种类型的样本量\n",
    "\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1] # 获取样本的分类\n",
    "        if currentLabel not in labelCounts.keys(): # 发现新类类型\n",
    "            labelCounts[currentLabel] = 0 # 初始化新类型的样本量\n",
    "        labelCounts[currentLabel] += 1 # 对该种类型的样本量加一\n",
    "\n",
    "    shannonEnt = 0.0 # 初始化信息熵\n",
    "    for key in labelCounts:\n",
    "        probabillity = float(labelCounts[key]) / numEntries # 计算每个分类出现的概率\n",
    "        shannonEnt -= probabillity * log(probabillity, 2) # 累计香农信息熵\n",
    "\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet, axis, value):\n",
    "    \"\"\"\n",
    "    function: 根据某个特征的某个值，分离出一个该特征值下面的子样本集，同时从样本集去除特征（方便外部迭代）\n",
    "    dataSet: type List[List[]]\n",
    "    axis: type int\n",
    "    value: type int/string\n",
    "    return: type List[List[]]\n",
    "    \"\"\"\n",
    "    retDataSet = [] # 返回满足给定特征的样本\n",
    "    for featVect in dataSet: # 遍历每个样本\n",
    "        if featVect[axis] == value: # 判断样本的目标特征是否符合目标值\n",
    "            reduceFeatVec = featVect[:axis]\n",
    "            reduceFeatVec.extend(featVect[axis + 1:])\n",
    "            retDataSet.append(reduceFeatVec) # 将该样本单独分离出来，剔除该属性值\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    \"\"\"\n",
    "    function:计算一个样本集中的最大信息增益的特征\n",
    "    dataSet: type List[List[]]\n",
    "    return: type int\n",
    "    \"\"\"\n",
    "    numFeatures = len(dataSet[0]) - 1 # 计算总特征数量（-1是因为有一个item存储的是分类，不是特征）\n",
    "    baseEntropy = calcShannonEnt(dataSet) # 计算整体样本的信息熵\n",
    "    bestInfoGain = 0.0 # 初始化信息增益\n",
    "    bestFeature = -1 # 初始化最优特征\n",
    "    for i in range(numFeatures): # 对于每种特征\n",
    "        featList = [example[i] for example in dataSet] # 抽取该特征的所有标称量\n",
    "        uniqueVals = set(featList) # 对所有标称量进行去重，获得标称量的枚举\n",
    "        newEntropy = 0.0 # 初始化划分样本后的信息熵\n",
    "        for value in uniqueVals: # 对于该特征的每个标称值\n",
    "            subDataSet = splitDataSet(dataSet, i, value) # 对第i个特征，标称值为value的样本，抽离出一个子样本集\n",
    "            prob = len(subDataSet) / float(len(dataSet)) # 计算该样本集在整体样本中的出现概率\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet) # 累计该特征划分后的信息熵\n",
    "        infoGain = baseEntropy - newEntropy # 计算该划分下的信息增益\n",
    "        if (infoGain > bestInfoGain) : # 留下最大的信息增益特征\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majorityCnt(classList):\n",
    "    \"\"\"\n",
    "    input : array [] 剩余分类的列表\n",
    "    \"\"\"\n",
    "    classCount = {} # 用于存储分类的个数\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys(): # 如果没有过该分类\n",
    "            classCount[vote] = 0 # 为此分类初始化为0\n",
    "        classCount[vote] += 1 # 否则对此分类增加1\n",
    "    sortedClassCount = sorted(classCount.iteritems(), key = operator.itemgetter(1), reverse = True) # 根据分类对应次数从大到小排序\n",
    "    return sortedClassCount[0][0] # 返回最多的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataSet, labels):\n",
    "    \"\"\"\n",
    "    function:跟进最优特征划分，将样本集划分成决策树\n",
    "    dataSet: type List[List[]]\n",
    "    labels: type List[string]\n",
    "    \"\"\"\n",
    "    classList = [example[-1] for example in dataSet] # 提取所有的分类\n",
    "\n",
    "    # 结束条件判断\n",
    "    if classList.count(classList[0]) == len(classList): # 结束条件1：如果只有一种分类，即随机取一个分类，分类的数量刚好等于总数量\n",
    "        return classList[0] # 返回该特征作为叶子\n",
    "    if len(dataSet[0]) == 1: # 结束条件2：如果只剩下分类了，即所有特征都分离完了\n",
    "        return majorityCnt(classList) # 选择一种出现最多次数的分类，作为叶子（不过这样应该会有一定的错误率）\n",
    "\n",
    "    # 最优特征选取\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet) # 选出最优特征\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "\n",
    "    # 构建结果\n",
    "    myTree = {bestFeatLabel:{}} # 初始化决策树\n",
    "    del(labels[bestFeat]) # 删除已选出的标签\n",
    "\n",
    "    featValues = [example[bestFeat] for example in dataSet] # 选出最有特征在样本集中的特征值\n",
    "    uniqueVals = set(featValues) # 去重，得到最优特征的特征值集合\n",
    "\n",
    "    # 迭代构建\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]  # 由于python的引用传参，会导致该变量在递归中被修改，因此复制一个副本进行传递\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels) # 对最有特征的每个值进行样本抽离，迭代计算决策树\n",
    "\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "# run\n",
    "data, labels = createDataSet()\n",
    "tree = createTree(data, labels)\n",
    "print tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
